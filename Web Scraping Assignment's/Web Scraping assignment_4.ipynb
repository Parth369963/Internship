{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fb88ce1",
   "metadata": {},
   "source": [
    "# >>>>>>>>>>>>> WEB SCRAPING ‚Äì ASSIGNMENT 4<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b4097",
   "metadata": {},
   "source": [
    "### Parth Makwana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c69aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27710163",
   "metadata": {},
   "source": [
    "### 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "**You need to find following details:**\n",
    "\n",
    "- A) Rank\n",
    "- B) Name\n",
    "- C) Artist\n",
    "- D) Upload date\n",
    "- E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c940e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "\n",
    "# Opening the homepage\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a108de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty lists\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "UploadDate = []\n",
    "Views = []\n",
    "\n",
    "# Scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    \n",
    "    \n",
    "#scrapping name\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"_\")\n",
    "    \n",
    "    \n",
    "#scrapping Artist\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[3]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"_\")\n",
    "    \n",
    "    \n",
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,' //table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        UploadDate.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    UploadDate.append('-')\n",
    "# Scraping Views of videos\n",
    "\n",
    "\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f310f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(Name),len(Artist),len(UploadDate),len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d589526",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = pd.DataFrame({})\n",
    "wikipedia['Rank']=Rank\n",
    "wikipedia['Name']=Name\n",
    "wikipedia['Artist']=Artist\n",
    "wikipedia['Upload Date']=UploadDate\n",
    "wikipedia['Views']=Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc424648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon ‚Äì Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[24]</td>\n",
       "      <td>Cocomelon ‚Äì Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[25]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors ‚Äì Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear ‚Äì Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Axel F\"[35]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[36]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[37]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon ‚Äì Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[41]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"[43]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Girls Like You\"[45]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi ‚Äì Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[50]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                          \"Wheels on the Bus\"[24]   \n",
       "8    9.                                \"Uptown Funk\"[25]   \n",
       "9   10.  \"Learning Colors ‚Äì Colorful Eggs on a Farm\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear ‚Äì Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                     \"Axel F\"[35]   \n",
       "15  16.                                       \"Roar\"[36]   \n",
       "16  17.                             \"Counting Stars\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"[41]   \n",
       "21  22.                                 \"Dark Horse\"[42]   \n",
       "22  23.                                      \"Faded\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.                             \"Girls Like You\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                             \"Lakdi Ki Kathi\"[50]   \n",
       "\n",
       "                                           Artist        Upload Date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  12.27  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.08  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.61  \n",
       "3                      Cocomelon ‚Äì Nursery Rhymes        May 2, 2018   6.01  \n",
       "4                                      Ed Sheeran   January 30, 2017   5.91  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.78  \n",
       "6                                       ChuChu TV      March 6, 2014   5.15  \n",
       "7                      Cocomelon ‚Äì Nursery Rhymes       May 24, 2018   4.92  \n",
       "8                                     Mark Ronson  November 19, 2014   4.83  \n",
       "9                                     Miroshka TV  February 27, 2018   4.81  \n",
       "10                                            Psy      July 15, 2012   4.69  \n",
       "11                                     Get Movies   January 31, 2012   4.53  \n",
       "12                                      El Chombo      April 5, 2018   4.23  \n",
       "13                                       Maroon 5   January 14, 2015   3.82  \n",
       "14                                     Crazy Frog      June 16, 2009   3.75  \n",
       "15                                     Katy Perry  September 5, 2013   3.73  \n",
       "16                                    OneRepublic       May 31, 2013   3.72  \n",
       "17                                  Justin Bieber   October 22, 2015   3.63  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.55  \n",
       "19                     Cocomelon ‚Äì Nursery Rhymes      June 25, 2018   3.49  \n",
       "20                                        Shakira       June 4, 2010   3.47  \n",
       "21                                     Katy Perry  February 20, 2014   3.45  \n",
       "22                                    Alan Walker   December 3, 2015   3.40  \n",
       "23                                      Passenger      July 25, 2012   3.38  \n",
       "24                                       Maroon 5       May 31, 2018   3.37  \n",
       "25                                     Ed Sheeran   November 9, 2017   3.37  \n",
       "26                               Enrique Iglesias     April 11, 2014   3.33  \n",
       "27                                    Major Lazer     March 22, 2015   3.33  \n",
       "28  Kiddiestv Hindi ‚Äì Nursery Rhymes & Kids Songs   January 26, 2018   3.30  \n",
       "29                                   Jingle Toons      June 14, 2018   3.30  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a3f85",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team India‚Äôs internationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "**You need to find following details:**\n",
    "\n",
    "- A) Match title (I.e. 1stODI)\n",
    "- B) Series\n",
    "- C) Place\n",
    "- D) Date\n",
    "- E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965fdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the homepage\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0120eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "International = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a') # click button\n",
    "International.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4aa5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "#Scrapping Name\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]'):\n",
    "        Name.append(i.text.replace('-',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "    \n",
    "#Scrapping Series\n",
    "try:\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]'):\n",
    "        Series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append('-')\n",
    "    \n",
    "#scrapping Place\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "        Place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Place.append('-')\n",
    "    \n",
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('-')\n",
    "    \n",
    "#Scrapping Time\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]'):\n",
    "        Time.append(i.text.replace('IST',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Time.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07392965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Newlands,</td>\n",
       "      <td>12 FEB 2023</td>\n",
       "      <td>6:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Newlands,</td>\n",
       "      <td>15 FEB 2023</td>\n",
       "      <td>6:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>2nd Test</td>\n",
       "      <td>Arun Jaitley Stadium,</td>\n",
       "      <td>17 FEB 2023</td>\n",
       "      <td>9:30 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>St George's Park,</td>\n",
       "      <td>18 FEB 2023</td>\n",
       "      <td>6:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>4th T20I</td>\n",
       "      <td>St George's Park,</td>\n",
       "      <td>20 FEB 2023</td>\n",
       "      <td>6:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>3rd Test</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,</td>\n",
       "      <td>1 MAR 2023</td>\n",
       "      <td>9:30 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>Narendra Modi Stadium,</td>\n",
       "      <td>9 MAR 2023</td>\n",
       "      <td>9:30 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>17 MAR 2023</td>\n",
       "      <td>1:30 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Title       Name  \\\n",
       "0                ICC WOMENS T20 WORLD CUP 2023  1st T20I    \n",
       "1                ICC WOMENS T20 WORLD CUP 2023  2nd T20I    \n",
       "2  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23  2nd Test    \n",
       "3                ICC WOMENS T20 WORLD CUP 2023  3rd T20I    \n",
       "4                ICC WOMENS T20 WORLD CUP 2023  4th T20I    \n",
       "5  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23  3rd Test    \n",
       "6  AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23  4th Test    \n",
       "7   AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23   1st ODI    \n",
       "\n",
       "                                           Place         Date      Time  \n",
       "0                                      Newlands,  12 FEB 2023  6:30 PM   \n",
       "1                                      Newlands,  15 FEB 2023  6:30 PM   \n",
       "2                          Arun Jaitley Stadium,  17 FEB 2023  9:30 AM   \n",
       "3                              St George's Park,  18 FEB 2023  6:30 PM   \n",
       "4                              St George's Park,  20 FEB 2023  6:30 PM   \n",
       "5  Himachal Pradesh Cricket Association Stadium,   1 MAR 2023  9:30 AM   \n",
       "6                         Narendra Modi Stadium,   9 MAR 2023  9:30 AM   \n",
       "7                              Wankhede Stadium,  17 MAR 2023  1:30 PM   "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fixtures=pd.DataFrame({})\n",
    "Fixtures['Title']=Series\n",
    "Fixtures['Name']=Name\n",
    "Fixtures['Place']=Place\n",
    "Fixtures['Date']=Date\n",
    "Fixtures['Time']=Time\n",
    "Fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bce612",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "**You have to find following details:**\n",
    "\n",
    "- A) Rank\n",
    "- B) State\n",
    "- C) GSDP(18-19)- at current prices\n",
    "- D) GSDP(19-20)- at current prices\n",
    "- E) Share(18-19)\n",
    "- F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d822491",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56356da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "847d4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div[1]/div/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b605055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Economy button\n",
    "driver.find_element(By.XPATH,\"//div[@class='navbar']/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f45eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on India\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8132a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f70f16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDPbillion = []\n",
    "# Scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "# Scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "# Scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "# Scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "# Scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDPbillion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDPbillion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b69ff25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RANK</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP2</th>\n",
       "      <th>SHARE</th>\n",
       "      <th>GDPbillion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RANK                      STATE      GSDP2   SHARE GDPbillion\n",
       "0     1                Maharashtra  2,632,792  13.94%    399.921\n",
       "1     2                 Tamil Nadu  1,630,208   8.63%    247.629\n",
       "2     3              Uttar Pradesh  1,584,764   8.39%    240.726\n",
       "3     4                    Gujarat  1,502,899   7.96%    228.290\n",
       "4     5                  Karnataka  1,493,127   7.91%    226.806\n",
       "..  ...                        ...        ...     ...        ...\n",
       "61   29                     Sikkim     25,141   0.15%     17,060\n",
       "62   30                   Nagaland     24,534   0.15%          -\n",
       "63   31          Arunachal Pradesh     22,488   0.13%          -\n",
       "64   32                    Mizoram     20,947   0.13%     17,797\n",
       "65   33  Andaman & Nicobar Islands          -       -          -\n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDIA=pd.DataFrame()\n",
    "INDIA['RANK']=Rank\n",
    "INDIA['STATE']=State\n",
    "INDIA['GSDP2']=GSDP2\n",
    "INDIA['SHARE']=Share\n",
    "INDIA['GDPbillion']=GDPbillion\n",
    "INDIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68657bb",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "\n",
    "**You have to find the following details:**\n",
    "\n",
    "- A) Repository title\n",
    "- B) Repository description\n",
    "- C) Contributors count\n",
    "- D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa65c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(\" https://github.com/\")\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2fd6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[1]/div[2]/button/span/span/div[2]\")\n",
    "try:\n",
    "    explore.click()\n",
    "    time.sleep(5)\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(explore.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6aa5442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opensource = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43ad94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on Trending\n",
    "\n",
    "trending = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42011755",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLs = []\n",
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []\n",
    "\n",
    "#Fetching urls for each repository\n",
    "repository = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "for i in repository:\n",
    "    URLs.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0a965c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Repository Title data\n",
    "title = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']\")\n",
    "for i in title:\n",
    "    repository_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bdbcb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data from all repository page\n",
    "for i in URLs:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "# Scraping Repository Description data\n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH,\"//p[@class='f4 my-3']\")\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "# Scraping Contributors Count data\n",
    "    try:\n",
    "        contributor = driver.find_element(By.XPATH,\"//*[contains(text(),'    Contributors ')]\")\n",
    "        Contributors.append(contributor.text.replace('Contributors',''))\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "        \n",
    "        \n",
    "# Scraping Languages used data\n",
    "    lang=[]\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]'):\n",
    "            lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e1aa2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(repository_title),len(Description),len(Contributors),len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51481615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acikkaynak / deprem-yardim-backend-go</td>\n",
       "      <td>-</td>\n",
       "      <td>16</td>\n",
       "      <td>[Go, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cloudflare / wildebeest</td>\n",
       "      <td>Wildebeest is an ActivityPub and Mastodon-comp...</td>\n",
       "      <td>12</td>\n",
       "      <td>[TypeScript, JavaScript, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jaymody / picoGPT</td>\n",
       "      <td>An unnecessarily tiny and minimal implementati...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eliaszon / Programmers-Overseas-Job-Interview-...</td>\n",
       "      <td>üèÇüèª Á®ãÂ∫èÂëòÊµ∑Â§ñÂ∑•‰Ωú/Ëã±ÊñáÈù¢ËØïÊâãÂÜå</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uutils / coreutils</td>\n",
       "      <td>Cross-platform Rust rewrite of the GNU coreutils</td>\n",
       "      <td>351</td>\n",
       "      <td>[Rust, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rustdesk / rustdesk</td>\n",
       "      <td>Open source virtual / remote desktop infrastru...</td>\n",
       "      <td>156</td>\n",
       "      <td>[Rust, Dart, C, C++, Kotlin, Python, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MichalGeyer / plug-and-play</td>\n",
       "      <td>Official Pytorch Implementation for ‚ÄúPlug-and-...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pedroslopez / whatsapp-web.js</td>\n",
       "      <td>A WhatsApp client library for NodeJS that conn...</td>\n",
       "      <td>84</td>\n",
       "      <td>[JavaScript, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>djun / wechatbot</td>\n",
       "      <td>‰∏∫‰∏™‰∫∫ÂæÆ‰ø°Êé•ÂÖ•ChatGPT</td>\n",
       "      <td>-</td>\n",
       "      <td>[Go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fuergaosi233 / wechat-chatgpt</td>\n",
       "      <td>Use ChatGPT On Wechat via wechaty</td>\n",
       "      <td>25</td>\n",
       "      <td>[TypeScript, Dockerfile, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TheD1rkMtr / FilelessPELoader</td>\n",
       "      <td>Loading Remote AES Encrypted PE in memory , De...</td>\n",
       "      <td>-</td>\n",
       "      <td>[C++, Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>eryajf / chatgpt-dingtalk</td>\n",
       "      <td>ChatGPTÊú∫Âô®‰∫∫Âú®ÈíâÈíâÁæ§ËÅä‰∏≠‰∫§‰∫í</td>\n",
       "      <td>-</td>\n",
       "      <td>[Go, Dockerfile, Makefile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aquasecurity / trivy</td>\n",
       "      <td>Find vulnerabilities, misconfigurations, secre...</td>\n",
       "      <td>279</td>\n",
       "      <td>[Go, Smarty, Shell, Open Policy Agent, Makefil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ethereum-optimism / op-analytics</td>\n",
       "      <td>On-Chain Data, Utilities, References, and othe...</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nerfstudio-project / nerfstudio</td>\n",
       "      <td>A collaboration friendly studio for NeRFs</td>\n",
       "      <td>75</td>\n",
       "      <td>[Python, JavaScript, Cuda, Shell, SCSS, TypeSc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AIGCT / EASYChatGPT</td>\n",
       "      <td>This is an application project of 'chatgpt',on...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>leminlimez / Cowabunga</td>\n",
       "      <td>iOS 14.0-15.7.1 &amp; 16.0-16.1.2 MacDirtyCow ToolBox</td>\n",
       "      <td>6</td>\n",
       "      <td>[Swift, Objective-C, C, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PlexPt / chatgpt-java</td>\n",
       "      <td>ChatGPT Java SDK. Lightweight package for inte...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Java]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Shopify / hydrogen</td>\n",
       "      <td>Hydrogen is Shopify‚Äôs stack for headless comme...</td>\n",
       "      <td>20</td>\n",
       "      <td>[TypeScript, JavaScript, CSS, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fndroid / clash_for_windows_pkg</td>\n",
       "      <td>A Windows/macOS GUI based on Clash</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>f / awesome-chatgpt-prompts</td>\n",
       "      <td>This repo includes ChatGPT prompt curation to ...</td>\n",
       "      <td>59</td>\n",
       "      <td>[HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>enhuiz / vall-e</td>\n",
       "      <td>An unofficial PyTorch implementation of the au...</td>\n",
       "      <td>-</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>zhayujie / chatgpt-on-wechat</td>\n",
       "      <td>‰ΩøÁî®ChatGPTÊê≠Âª∫ÂæÆ‰ø°ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂü∫‰∫éOpenAI APIÂíåitchatÂÆûÁé∞„ÄÇWecha...</td>\n",
       "      <td>7</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Leizhenpeng / feishu-chatGpt</td>\n",
       "      <td>Feishu ChatGpt Âú®È£û‰π¶‰∏ä‰∏éChatGPTÈöèÊó∂ÂØπËØù~</td>\n",
       "      <td>3</td>\n",
       "      <td>[Go, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>activepieces / activepieces</td>\n",
       "      <td>No-code Business Automation Tool. An open sour...</td>\n",
       "      <td>18</td>\n",
       "      <td>[TypeScript, HTML, SCSS, JavaScript, Dockerfil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository title  \\\n",
       "0               acikkaynak / deprem-yardim-backend-go   \n",
       "1                             cloudflare / wildebeest   \n",
       "2                                   jaymody / picoGPT   \n",
       "3   eliaszon / Programmers-Overseas-Job-Interview-...   \n",
       "4                                  uutils / coreutils   \n",
       "5                                 rustdesk / rustdesk   \n",
       "6                         MichalGeyer / plug-and-play   \n",
       "7                       pedroslopez / whatsapp-web.js   \n",
       "8                                    djun / wechatbot   \n",
       "9                       fuergaosi233 / wechat-chatgpt   \n",
       "10                      TheD1rkMtr / FilelessPELoader   \n",
       "11                          eryajf / chatgpt-dingtalk   \n",
       "12                               aquasecurity / trivy   \n",
       "13                   ethereum-optimism / op-analytics   \n",
       "14                    nerfstudio-project / nerfstudio   \n",
       "15                                AIGCT / EASYChatGPT   \n",
       "16                             leminlimez / Cowabunga   \n",
       "17                              PlexPt / chatgpt-java   \n",
       "18                                 Shopify / hydrogen   \n",
       "19                    Fndroid / clash_for_windows_pkg   \n",
       "20                        f / awesome-chatgpt-prompts   \n",
       "21                                    enhuiz / vall-e   \n",
       "22                       zhayujie / chatgpt-on-wechat   \n",
       "23                       Leizhenpeng / feishu-chatGpt   \n",
       "24                        activepieces / activepieces   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0                                                   -                 16   \n",
       "1   Wildebeest is an ActivityPub and Mastodon-comp...                 12   \n",
       "2   An unnecessarily tiny and minimal implementati...                  -   \n",
       "3                                   üèÇüèª Á®ãÂ∫èÂëòÊµ∑Â§ñÂ∑•‰Ωú/Ëã±ÊñáÈù¢ËØïÊâãÂÜå                  -   \n",
       "4    Cross-platform Rust rewrite of the GNU coreutils                351   \n",
       "5   Open source virtual / remote desktop infrastru...                156   \n",
       "6   Official Pytorch Implementation for ‚ÄúPlug-and-...                  2   \n",
       "7   A WhatsApp client library for NodeJS that conn...                 84   \n",
       "8                                      ‰∏∫‰∏™‰∫∫ÂæÆ‰ø°Êé•ÂÖ•ChatGPT                  -   \n",
       "9                   Use ChatGPT On Wechat via wechaty                 25   \n",
       "10  Loading Remote AES Encrypted PE in memory , De...                  -   \n",
       "11                                 ChatGPTÊú∫Âô®‰∫∫Âú®ÈíâÈíâÁæ§ËÅä‰∏≠‰∫§‰∫í                  -   \n",
       "12  Find vulnerabilities, misconfigurations, secre...                279   \n",
       "13  On-Chain Data, Utilities, References, and othe...                  -   \n",
       "14          A collaboration friendly studio for NeRFs                 75   \n",
       "15  This is an application project of 'chatgpt',on...                  -   \n",
       "16  iOS 14.0-15.7.1 & 16.0-16.1.2 MacDirtyCow ToolBox                  6   \n",
       "17  ChatGPT Java SDK. Lightweight package for inte...                  -   \n",
       "18  Hydrogen is Shopify‚Äôs stack for headless comme...                 20   \n",
       "19                 A Windows/macOS GUI based on Clash                  3   \n",
       "20  This repo includes ChatGPT prompt curation to ...                 59   \n",
       "21  An unofficial PyTorch implementation of the au...                  -   \n",
       "22  ‰ΩøÁî®ChatGPTÊê≠Âª∫ÂæÆ‰ø°ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂü∫‰∫éOpenAI APIÂíåitchatÂÆûÁé∞„ÄÇWecha...                  7   \n",
       "23                   Feishu ChatGpt Âú®È£û‰π¶‰∏ä‰∏éChatGPTÈöèÊó∂ÂØπËØù~                  3   \n",
       "24  No-code Business Automation Tool. An open sour...                 18   \n",
       "\n",
       "                                        Language used  \n",
       "0                                         [Go, Other]  \n",
       "1                     [TypeScript, JavaScript, Other]  \n",
       "2                                            [Python]  \n",
       "3                                                  []  \n",
       "4                                       [Rust, Other]  \n",
       "5         [Rust, Dart, C, C++, Kotlin, Python, Other]  \n",
       "6                                            [Python]  \n",
       "7                                 [JavaScript, Shell]  \n",
       "8                                                [Go]  \n",
       "9                     [TypeScript, Dockerfile, Shell]  \n",
       "10                                      [C++, Python]  \n",
       "11                         [Go, Dockerfile, Makefile]  \n",
       "12  [Go, Smarty, Shell, Open Policy Agent, Makefil...  \n",
       "13                                                 []  \n",
       "14  [Python, JavaScript, Cuda, Shell, SCSS, TypeSc...  \n",
       "15                                           [Python]  \n",
       "16                     [Swift, Objective-C, C, Shell]  \n",
       "17                                             [Java]  \n",
       "18               [TypeScript, JavaScript, CSS, Shell]  \n",
       "19                                                 []  \n",
       "20                                             [HTML]  \n",
       "21                                    [Python, Shell]  \n",
       "22                                           [Python]  \n",
       "23                                   [Go, Dockerfile]  \n",
       "24  [TypeScript, HTML, SCSS, JavaScript, Dockerfil...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Frame\n",
    "\n",
    "Github=pd.DataFrame({})\n",
    "Github['Repository title'] = repository_title\n",
    "Github['Repository description'] = Description\n",
    "Github['Contributors count'] = Contributors\n",
    "Github['Language used'] = Language\n",
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85299759",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "\n",
    "**You have to find the following details:**\n",
    "- A) Song name\n",
    "- B) Artist name\n",
    "- C) Last week rank\n",
    "- D) Peak rank\n",
    "- E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "94a481c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url=(\"https://www.billboard.com\")\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f6210bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23749251",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84816c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Artist=[]\n",
    "rank=[]\n",
    "\n",
    "#Scraping name\n",
    "Name_tag=driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet']\")\n",
    "for i in Name_tag:\n",
    "    Name.append(i.text)\n",
    "\n",
    "#Scraping artist\n",
    "Artist_tag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\")\n",
    "for i in Artist_tag:\n",
    "    Artist.append(i.text)\n",
    "\n",
    "#Scraping rank\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "for i in rankTag[:3]:\n",
    "    rank.append(i.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c36834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping name\n",
    "Rank=[]\n",
    "nameTag=driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in nameTag:\n",
    "    Name.append(i.text )\n",
    "\n",
    "#Scraping artist\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in artistTag:\n",
    "    Artist.append(i.text )\n",
    "\n",
    "#Scraping rank\n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "for i in RankTag:\n",
    "    Rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e44f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a2aaa843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing Data\n",
    "last_week_rank=Rank[0::3]\n",
    "last_week_rank.insert(0,rank[0])\n",
    "peak_rank=Rank[1::3]\n",
    "peak_rank.insert(0,rank[1])\n",
    "weeks_on_board=Rank[2::3]\n",
    "weeks_on_board.insert(0,rank[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "46ebc0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 133, 133, 133)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length of all\n",
    "len(Name),len(Artist),len(last_week_rank),len(peak_rank),len(weeks_on_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "237c4ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks On Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creepin'</td>\n",
       "      <td>Metro Boomin, The Weeknd &amp; 21 Savage</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hey Mor</td>\n",
       "      <td>Ozuna Featuring Feid</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Gato de Noche</td>\n",
       "      <td>Nengo Flow &amp; Bad Bunny</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heart To Heart</td>\n",
       "      <td>Mac DeMarco</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Never Gonna Not Dance Again</td>\n",
       "      <td>P!nk</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dancin' In The Country</td>\n",
       "      <td>Tyler Hubbard</td>\n",
       "      <td>71</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name                                Artist  \\\n",
       "0                       Flowers                           Miley Cyrus   \n",
       "1                     Kill Bill                                   SZA   \n",
       "2                      Creepin'  Metro Boomin, The Weeknd & 21 Savage   \n",
       "3                     Anti-Hero                          Taylor Swift   \n",
       "4                        Unholy                Sam Smith & Kim Petras   \n",
       "..                          ...                                   ...   \n",
       "95                      Hey Mor                  Ozuna Featuring Feid   \n",
       "96                Gato de Noche                Nengo Flow & Bad Bunny   \n",
       "97               Heart To Heart                           Mac DeMarco   \n",
       "98  Never Gonna Not Dance Again                                  P!nk   \n",
       "99       Dancin' In The Country                         Tyler Hubbard   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks On Board  \n",
       "0               1         1              3  \n",
       "1               2         2              8  \n",
       "2               4         3              9  \n",
       "3               3         1             15  \n",
       "4               5         1             19  \n",
       "..            ...       ...            ...  \n",
       "95             81        81              2  \n",
       "96                                          \n",
       "97             75        68              7  \n",
       "98                                          \n",
       "99             71        22              9  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_top=pd.DataFrame({\"Name\":Name[:100],\"Artist\":Artist[:100],\"Last Week Rank\":last_week_rank[0:100],\"Peak Rank\":peak_rank[0:100],\"Weeks On Board\":weeks_on_board[0:100]})\n",
    "songs_top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6895f7",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "\n",
    "**You have to find the following details:**\n",
    "\n",
    "- A) Book name\n",
    "- B) Author name\n",
    "- C) Volumes sold\n",
    "- D) Publisher\n",
    "- E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6cc87d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "66b0745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Bookname = []\n",
    "Authorname = []\n",
    "Volumessold = []\n",
    "Publisher = []\n",
    "Genre = []\n",
    "\n",
    "#scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr/td[2]\"):\n",
    "    Bookname.append(i.text)\n",
    "    \n",
    "#Scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Authorname.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Authorname.append('-')\n",
    "time.sleep(1)\n",
    "\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[4]\"):\n",
    "    Volumessold.append(i.text)\n",
    "    \n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9297b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Bookname),len(Authorname),len(Volumessold),len(Publisher),len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "67e30e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe for scraped data\n",
    "Novels=pd.DataFrame({})\n",
    "Novels['Book Name'] = Bookname\n",
    "Novels['Author'] = Authorname\n",
    "Novels['Volume sold'] = Volumessold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc7a3e",
   "metadata": {},
   "source": [
    "### 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "**You have to find the following details:**\n",
    "\n",
    "- A) Name\n",
    "- B) Year span\n",
    "- C) Genre\n",
    "- D) Run time\n",
    "- E) Ratings\n",
    "- F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "204e6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url = \" https://www.imdb.com/list/ls095964455/ \"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "609fde93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists.\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n",
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f086b266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Year_span),len(Run_time),len(Ratings),len(Genre),len(Votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5eb59b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011‚Äì2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,123,265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016‚Äì2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,211,191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010‚Äì2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,007,067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>297,137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014‚Äì2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>256,063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013‚Äì2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017‚Äì2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>62,619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005‚Äì )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>202,955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015‚Äì2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>42,044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>250,781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011‚Äì2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016‚Äì2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010‚Äì2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017‚Äì2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014‚Äì2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013‚Äì2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017‚Äì2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005‚Äì )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015‚Äì2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,123,265  \n",
       "1    51 min     8.7  1,211,191  \n",
       "2    44 min     8.1  1,007,067  \n",
       "3    60 min     7.5    297,137  \n",
       "4    43 min     7.6    256,063  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,733  \n",
       "96   50 min     7.8     62,619  \n",
       "97   42 min     8.1    202,955  \n",
       "98   45 min     7.1     42,044  \n",
       "99  572 min     8.6    250,781  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series=pd.DataFrame({})\n",
    "series['Name'] = Name\n",
    "series['Year Span'] = Year_span\n",
    "series['Genre'] = Genre\n",
    "series['Run Time'] = Run_time\n",
    "series['Ratings'] = Ratings\n",
    "series['Votes'] = Votes\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903cc872",
   "metadata": {},
   "source": [
    "### 8. Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "**You have to find the following details:**\n",
    "\n",
    "- A) Dataset name\n",
    "- B) Data type\n",
    "- C) Task\n",
    "- D) Attribute type\n",
    "- E) No of instances\n",
    "- F) No of attribute\n",
    "- G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9a00c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fe0d97fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset= driver.find_elements(By.XPATH,\"//span[@class='normal']/b/a\")[0].get_attribute('href')\n",
    "driver.get(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4c309209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping dataset\n",
    "data=[]\n",
    "try:\n",
    "    data_tag=driver.find_elements(By.XPATH,\"//td//p[@class='normal']\")\n",
    "    for i in data_tag[8:4362]:\n",
    "        data.append(i.text )\n",
    "except:\n",
    "    data.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "398ba4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing dataset\n",
    "Dataset_name=data[::7]\n",
    "Data_type=data[1::7]\n",
    "Task=data[2::7]\n",
    "Attribute_type=data[3::7]\n",
    "instances=data[4::7]\n",
    "attribute=data[5::7]\n",
    "Year=data[6::7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fbf7f2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 622 622 622 622 622 622\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset_name), len(Data_type), len(Task), len(Attribute_type), len(instances), len(attribute), len(Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d6f246bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute type Instances Attribute   Year  \n",
       "0    Categorical, Integer, Real      4177         8   1995   \n",
       "1          Categorical, Integer     48842        14   1996   \n",
       "2    Categorical, Integer, Real       798        38          \n",
       "3                   Categorical     37711       294   1998   \n",
       "4    Categorical, Integer, Real       452       279   1998   \n",
       "..                           ...       ...       ...    ...  \n",
       "617               Integer, Real     75840       525   2020   \n",
       "618               Integer, Real       400        50   2020   \n",
       "619                                  1014         7   2020   \n",
       "620                        Real     10129        16   2021   \n",
       "621                        Real      4000         2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datasets= pd.DataFrame({\"Dataset name\":Dataset_name,\"Data type\":Data_type,\"Task\":Task,\"Attribute type\":Attribute_type,\"Instances\":instances,\"Attribute\":attribute,\"Year\":Year})\n",
    "Datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
